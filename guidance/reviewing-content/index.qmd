---
title: "Reviewing content"
description: "Reviewing existing content and identifying new analyses"
author: "Matthew Wilson"
date: 2023-01-16

---

In line with the Code of Practice for Statistics, particularly principles [V1: Relevance to users](https://code.statisticsauthority.gov.uk/the-code/value/v1-relevance-to-users/#pid-table-of-guidance-and-resources) and [V4: Innovation and improvement](https://code.statisticsauthority.gov.uk/the-code/value/v4-innovation-and-improvement/), we should always be reviewing the content of our statistics to make sure that they provide public value and meet our user's needs. 

## Research, policy developments and media interests
As we begin the production for a new release of a publication the responsible statistician should make sure to familiarise themselves with the content of the publication including the data sources, and their quality, and any policy context/background that we have. A lot can change in the time between releases especially for our prescribing and medicines publications, keeping up to date with policy developments, the release of new prescribing guidance, and what has been in the media is essential. This research should be documented so that it can easily be referenced in the future.

## User and stakeholder feedback
Feedback collected through our continuous surveys, provided via email, or any other route should be reviewed and help guide any changes and improvements that we want to make to the statistics. This could include requests for new analyses, feedback on usability and clarity, or even feedback that an analysis is no longer needed. The views of interested stakeholders should also be regularly sought to make sure that the statistics fulfil their intended purpose. For example, colleagues at the Department for Health and Social Care (DHSC) and NHS England.

## New and emerging services
New services may become available that would be of interest to include in our publications, for example, a new advanced service for pharmacy contractors or a new service launched by the NHSBSA. Including data and analyses on these new services may provide new insights and increase the value of our statistics.

## Criteria and SME engagement
The criteria for our publications should also be reviewed to make sure that they are still relevant. For example, for publications in specific clinical areas such as Medicines Used in Mental Health and Prescribing for Diabetes the drug lists used should be reviewed and where appropriate the views of clinical colleagues should be sought. New products may have come to market or the BNF classifications of some existing products changed^[BNF changes occur in January of each year], We need to make sure that the drug lists that we use are up to date, comprehensive and clinically approved. Subject matter experts (SMEs) should be engaged here to provide guidance.

## Data quality issues
As with any data set mistakes can and do happen in our data. To make sure that we are aware of any data quality issues that may impact our statistics the data quality incident register maintained by the Data Governance team should be reviewed. Where a data quality issue is identified this should be noted and steps taken to correct the data or communicated to users what the issue is.

## Identified improvements and opportunities
We as statisticians often know of improvements that we can make to our outputs to make them more relevant to users or may have seen demonstrations of best practice from across the UK statistical system. During publication retrospectives ideas for improvements to take forward are logged and recorded as part of each publication's wiki. These ideas should be reviewed and where needed exploratory analysis carried out and documented.

## Methodological changes
We should always be reviewing the methodologies that we use in our statistics to make sure that they are recognised best practice and coherent with other statistics across the health and social care sector. If an improvement to a methodology is identified, for example, calculating standardised population rates or assigning patients to a particular lower-layer super output area (LSOA), then this improvement should be documented alongside any impacts that it may have on the statistics. There is not a dedicated methods group at the NHSBSA, however, other statisticians and analysts in the Data Analytics Learning Lab (DALL) and External Reporting teams should be invited to review the new methodology and discussions held on possible alternatives. Where practicable, all statisticians, data scientists, and analysts across the NHSBSA should be using standardised methods for analysis.

Where a new method is statistically innovative or a wholesale change from what has been used before it may be advised to consult the [Methodology Advisory Service(MAS)](https://www.ons.gov.uk/aboutus/whatwedo/paidservices/methodologyadvisoryservicemas) at the Office for National Statistics (ONS).

## User engagement and pre-announcing changes
Once a review of content has been completed all changes that have been decided to be carried forward for the new release should be documented in full, including additions/removal of content. The impacts of any changes should also be explored and documented, for example, if a methodological change is being made or if a data source is changing. The views of the NHSBSA Lead Official for Statistics and/or Statistical Publication Lead should then be sought on the proposed changes to provide guidance.

Any changes that we are making to the statistics **must** be pre-announced on the NHSBSA website well in advance of the release of the statistics (at least 4 weeks in advance). Where practicable, users views should be sought on the proposed changes, but were these changes have been guided by user feedback already this may not be necessary.

Where large methodological changes have taken place or where the underlying data source for the statistics has changed and materially impacted new or historical figures users views **must** be sought before the change is implemented --- particularly for National Statistics publications. User engagement can be done through a variety of methods, including:

* dedicated engagement events
* public consultations
* blogs detailing the changes and impacts
* other activities

User engagement is often done in conjunction with other teams throughout the organisation such as Communications and Customer Insight. These teams should be consulted to help support our engagement activities.

## checklist
* do you know what analyses are in the statistics and their data source?
* are all data sources still available?
* what policy developments have their been?
* have there been any FOI/data/PQ requests that show there is a gap in the statistics?
* are new services/areas for analysis available? Have any services stopped?
* have users provided any feedback that can be acted upon?
* have there been any data quality incidents that would impact the statistics?
* what areas did we identify for improvement from the previous release's debrief?
* have you documented the review process and formulated an improvement plan for the release
