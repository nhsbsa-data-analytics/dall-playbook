---
title: "Analysis and modelling"
description: "Analyse the data and create models to support the expected outputs."
image: 02-analysis-modelling.jpg
image-alt: Photo by Shubham Dhage on Unsplash
---

In this step, we turn our data into insights. The work done here can vary. It can include statistical analysis, both modelled and descriptive, as well as more sophisticated Machine Learning (AI) – the choice being dependent on the output requirements of the customer. The output can be presented in the form of a report, a dashboard, or a slide deck.

## Conducting the work
Starting from the source tables, we want to create the agreed outputs. Depending on the work, there are many approaches and tools we can use to do this.

* R is especially suited to use for statistical analysis and visualisation and supports reproducible (Rmarkdown) and interactive (R Shiny) reports.
* Python has most widespread support for training Artificial Intelligence Models and is more widely integrated with cloud-based platforms.
* Power BI is a possible alternative to R Shiny for creating dashboards, but due to licensing may not be suitable for certain end users.
* If it is appropriate, Excel and/or SQL can be used for generating simple summary statistics.

Please see the internal Data Science Wiki for tips on how to use all of these tools.

## Tips for effective analysis
* Select the most appropriate model or approach for the problem. Useful guidance can be found at:
    * [Good practice guidance: Framework to review models (nao.org.uk)](https://www.nao.org.uk/wp-content/uploads/2016/03/11018-002-Framework-to-review-models_External_4DP.pdf)
    * [Principles of quality assurance for modelling and data analysis (publishing.service.gov.uk)](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/878616/Principles_of_QA_for_analysis.pdf)
    * [The Aqua Book: guidance on producing quality analysis - GOV.UK (www.gov.uk)](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/878616/Principles_of_QA_for_analysis.pdf)
    * [Government Functional Standard (publishing.service.gov.uk)](https://assets.publishing.service.gov.uk/media/64e4cf0a4002ee000d560d5f/2023.02_GovS_010_Analysis_v2.1.pdf)

## Tips for effective programming
* Use Github to handle version control, issues and code reviews.
* In Python, use object-oriented programming (OOP) if you can. Please see the internal Data Science Wiki for information.
* Although R does have support for OOP, it is not a big paradigm like in Python.
* Be careful of premature optimisation (called out by computer scientist Donald Knuth as ‘the root of all evil’ in software development).
* Start small, such as limiting data to a manageable subset when developing the analysis; this makes it easier to spot issues and allows for faster iteration of code.
* Check the data looks correct at each step of reshaping and transforming it; better still, know what it should be before writing and applying the step (the principle behind test driven development, TDD).
* Work on one component of output at a time, for example using `shiny` with the modular `golem` framework, as in our [template](https://github.com/nhsbsa-data-analytics/nhsbsaShinyR).
* Frequently run code as you write it, so any issues are encountered early and their source is clearer.
* You may produce multiple smaller data sets to be used in your outputs; the considerations applying to base tables apply equally to these.
* Where appropriate, the final code should use RAP principles [LINK?].

## Check the quality
As with data preparation, it is important to test and validate your results.

* Where possible, check results against other sources.
* Other sources could be data from previous initiatives, Management Information dashboards or ePACT2.

Additionally, you must be careful about visualising sensitive results. Please contact your critical friend or the Data Science Lead if you are unsure. Results for external audience or general public must be subjected to Statistical Disclosure Control [LINK] before release.
Before pushing the code to GitHub, it's essential to ensure that the output is cleared, and that no sensitive information remains within it.

### RAP considerations (LINK?)
* It is worth spending time on making the data preparation easy to repeat.
* Make sure the code is easy to maintain, read and re-run when required.
* Rather than just doing adhoc testing, write formal tests that can be repeated.
* Working in a RAP-ful way is especially important when the output of an initiative is to be refreshed periodically, such as monthly or annually. Document your code as you go. Maintain a clear project structure with clean scripts.
* Separate data, scripts and output into their own sub-directories.
* Move custom functions into their own script.
* Document your custom functions.